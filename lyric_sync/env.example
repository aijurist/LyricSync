# Optional: Hugging Face token (not required for local faster-whisper)
# HF_TOKEN=your_hugging_face_token_here

# Whisper Model Configuration
# Options: tiny, base, small, medium, large-v2, large-v3
# - tiny: Fastest, lowest accuracy (~1GB RAM)
# - base: Good balance of speed and accuracy (~1GB RAM) [RECOMMENDED]
# - small: Better accuracy, slower (~2GB RAM)
# - medium: High accuracy, slower (~5GB RAM)
# - large-v2/large-v3: Best accuracy, slowest (~10GB RAM)
WHISPER_MODEL=base

# Device Configuration
# Options: auto, cpu, cuda
# - auto: Automatically detect GPU (recommended)
# - cpu: Force CPU usage
# - cuda: Force GPU usage (requires CUDA-compatible GPU)
WHISPER_DEVICE=auto

# Compute Type Configuration
# Options: auto, int8, float16, float32
# - auto: int8 for CPU, float16 for GPU (recommended)
# - int8: Lower memory, faster on CPU
# - float16: Better accuracy, requires GPU
# - float32: Highest accuracy, slower
WHISPER_COMPUTE_TYPE=auto

